# -*- coding: utf-8 -*-
"""Demorphing_using_KNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1frRtZ-3LqWE7GIeQuUebYeMwVZcqlnOd
"""

import dlib
import cv2
import numpy as np
import matplotlib.pyplot as plt
from IPython.display import display, Image
from scipy.spatial import Delaunay
from skimage import img_as_ubyte
from skimage.color import gray2rgb
from skimage.transform import warp, SimilarityTransform
import os
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from google.colab import drive
drive.mount('/content/drive')

def get_facial_landmarks(image_path):
    detector = dlib.get_frontal_face_detector()
    predictor = dlib.shape_predictor("/content/drive/MyDrive/shape_predictor_68_face_landmarks.dat")

    image = cv2.imread(image_path)
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    faces = detector(gray)
    if not faces:
        raise ValueError("No faces detected in the image.")

    landmarks = predictor(gray, faces[0])
    landmarks = [(p.x, p.y) for p in landmarks.parts()]

    return np.array(landmarks)

def align_images(source_image, target_image, source_landmarks, target_landmarks):
    transform = SimilarityTransform()
    transform.estimate(target_landmarks, source_landmarks)
    aligned_image = warp(source_image, transform, output_shape=target_image.shape)

    return img_as_ubyte(aligned_image)

def delaunay_triangulation(points):
    tri = Delaunay(points)
    return tri.simplices

def warp_images(source_image, target_image, source_triangles, target_triangles):
    morphed_image = np.zeros_like(target_image, dtype=np.float32)

    for source_triangle, target_triangle in zip(source_triangles, target_triangles):
        src_pts = source_triangle
        dst_pts = target_triangle

        warp_triangle(source_image, target_image, morphed_image, src_pts, dst_pts)

    return morphed_image.astype(np.uint8)

def warp_triangle(source_image, target_image, morphed_image, src_pts, dst_pts):
    assert len(dst_pts) >= 3, "At least 3 destination points are required for a triangle."

    print("dst_pts:", dst_pts)

    min_x = min(dst_pts[0][0], dst_pts[1][0], dst_pts[2][0])
    max_x = max(dst_pts[0][0], dst_pts[1][0], dst_pts[2][0])
    min_y = min(dst_pts[0][1], dst_pts[1][1], dst_pts[2][1])
    max_y = max(dst_pts[0][1], dst_pts[1][1], dst_pts[2][1])

    rect = (min_x, min_y, max_x - min_x, max_y - min_y)

    cropped_source = source_image[rect[1]:rect[1] + rect[3], rect[0]:rect[0] + rect[2]]
    cropped_target = target_image[rect[1]:rect[1] + rect[3], rect[0]:rect[0] + rect[2]]

    mask = get_triangle_mask(src_pts, rect)

    blended_triangle = poisson_blend(cropped_source, cropped_target, mask)

    morphed_image[rect[1]:rect[1] + rect[3], rect[0]:rect[0] + rect[2]] = blended_triangle




def get_triangle_mask(points, rect):
    mask = np.zeros((rect[3], rect[2]), dtype=np.uint8)
    cv2.fillPoly(mask, [np.array(points) - (rect[0], rect[1])], 255)
    return mask

def poisson_blend(source, target, mask):
    return cv2.seamlessClone(source, target, mask, (source.shape[1] // 2, source.shape[0] // 2), cv2.NORMAL_CLONE)

def load_images_from_directory(directory):
    image_paths = []
    for filename in os.listdir(directory):
        if filename.endswith(".jpg") or filename.endswith(".png"):
            image_paths.append(os.path.join(directory, filename))
    return image_paths

def load_chip_in_vivo_images(chip_directory, in_vivo_directory):
    chip_images = load_images_from_directory(chip_directory)
    in_vivo_images = load_images_from_directory(in_vivo_directory)

    chip_images.sort()
    in_vivo_images.sort()

    return chip_images, in_vivo_images

casia_webface_directory_path = "/content/drive/MyDrive/modified_dataset"

chip_subdirectory = "chip_image"
in_vivo_subdirectory = "vivo_image"

chip_directory_path = os.path.join(casia_webface_directory_path, chip_subdirectory)
in_vivo_directory_path = os.path.join(casia_webface_directory_path, in_vivo_subdirectory)

chip_images, in_vivo_images = load_chip_in_vivo_images(chip_directory_path, in_vivo_directory_path)


def create_autoencoder(input_shape):
    model = keras.Sequential([
        layers.InputLayer(input_shape=input_shape),
        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2), padding='same'),
        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2), padding='same'),
        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2), padding='same'),
        layers.Conv2DTranspose(256, (3, 3), activation='relu', padding='same'),
        layers.UpSampling2D((2, 2)),
        layers.Conv2DTranspose(128, (3, 3), activation='relu', padding='same'),
        layers.UpSampling2D((2, 2)),
        layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same'),
        layers.UpSampling2D((2, 2)),
        layers.Conv2DTranspose(3, (3, 3), activation='sigmoid', padding='same')
    ])
    return model


def create_demorphing_model(input_shape):
    autoencoder = create_autoencoder(input_shape)

    in_vivo_encoder = create_autoencoder(input_shape)
    chip_encoder = create_autoencoder(input_shape)

    in_vivo_image = layers.Input(shape=input_shape, name='vivo_image')
    chip_image = layers.Input(shape=input_shape, name='chip_image')

    in_vivo_embedding = in_vivo_encoder(in_vivo_image)
    chip_embedding = chip_encoder(chip_image)

    subtracted = layers.Subtract()([chip_embedding, in_vivo_embedding])
    demorphed_image = autoencoder(subtracted)

    demorphing_model = keras.Model(
        inputs=[in_vivo_image, chip_image],
        outputs=demorphed_image,
        name='demorphing_model'
    )

    return demorphing_model

def create_similarity_model(input_shape):
    similarity_model = keras.Sequential([
        layers.InputLayer(input_shape=input_shape),
        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2), padding='same'),
        layers.Flatten(),
        layers.Dense(256, activation='relu'),
        layers.Dense(1, activation='sigmoid')
    ])
    return similarity_model


input_shape = (224, 224, 3)
demorphing_model = create_demorphing_model(input_shape)
demorphing_model.compile(optimizer='adam', loss='mse')


similarity_model = create_similarity_model(input_shape)
similarity_model.compile(optimizer='adam', loss='binary_crossentropy')

def simple_morphing(image1, image2, alpha):
    return cv2.addWeighted(image1, alpha, image2, 1 - alpha, 0)

for chip_image_path, in_vivo_image_path in zip(chip_images, in_vivo_images):
    chip_landmarks = get_facial_landmarks(chip_image_path)
    in_vivo_landmarks = get_facial_landmarks(in_vivo_image_path)

    aligned_chip = align_images(cv2.imread(chip_image_path), cv2.imread(in_vivo_image_path), chip_landmarks, in_vivo_landmarks)

    chip_triangles = delaunay_triangulation(chip_landmarks)
    in_vivo_triangles = delaunay_triangulation(in_vivo_landmarks)

    alpha_values = np.linspace(0, 1, num=10)

    similarity_scores = []

    for alpha in alpha_values:
        morphed_image = simple_morphing(aligned_chip, cv2.imread(in_vivo_image_path), alpha)

        in_vivo_image = cv2.imread(in_vivo_image_path)
        in_vivo_image = cv2.resize(in_vivo_image, (224, 224))

        morphed_image_resized = cv2.resize(morphed_image, (224, 224))
        demorphed_image = demorphing_model.predict([np.expand_dims(in_vivo_image, axis=0), np.expand_dims(morphed_image_resized, axis=0)])[0]

        similarity_score = similarity_model.predict(np.expand_dims(demorphed_image, axis=0))[0][0]

        similarity_scores.append(similarity_score)

        #_, colab_image = cv2.imencode('.jpeg', cv2.cvtColor(demorphed_image, cv2.COLOR_BGR2RGB))
        #display(Image(data=colab_image))

    plt.plot(alpha_values, similarity_scores)

plt.xlabel('Alpha (Morphing Parameter)')
plt.ylabel('Similarity Score')
plt.legend()
plt.title('Similarity Score vs Morphing Parameter')
plt.show()

cv2.destroyAllWindows()

# Iteration Over Image Pairs
for chip_image_path, in_vivo_image_path in zip(chip_images, in_vivo_images):
    # Morphing Process
    chip_landmarks = get_facial_landmarks(chip_image_path)
    in_vivo_landmarks = get_facial_landmarks(in_vivo_image_path)

    aligned_chip = align_images(cv2.imread(chip_image_path), cv2.imread(in_vivo_image_path), chip_landmarks, in_vivo_landmarks)

    chip_triangles = delaunay_triangulation(chip_landmarks)
    in_vivo_triangles = delaunay_triangulation(in_vivo_landmarks)

    # Morphing using linear interpolation
    alpha_values = np.linspace(0, 1, num=10)  # Adjust the number of steps as needed

    for alpha in alpha_values:
        morphed_image = simple_morphing(aligned_chip, cv2.imread(in_vivo_image_path), alpha)

         #Display the morphed image in Colab
        _, colab_image = cv2.imencode('.jpeg', cv2.cvtColor(morphed_image, cv2.COLOR_BGR2RGB))
        display(Image(data=colab_image))

    cv2.destroyAllWindows()

    # De-morphing Process
    # De-morphing Process
    in_vivo_image = cv2.imread(in_vivo_image_path)
    in_vivo_image = cv2.resize(in_vivo_image, (224, 224))  # Resize to the expected input shape

    aligned_chip = cv2.resize(aligned_chip, (224, 224))  # Resize aligned_chip to the expected input shape

# Process the in_vivo_image using your de-morphing model
    demorphed_image = demorphing_model.predict([np.expand_dims(in_vivo_image, axis=0), np.expand_dims(aligned_chip, axis=0)])[0]

# Display the de-morphed image in Colab
    _, colab_image = cv2.imencode('.jpeg', cv2.cvtColor(demorphed_image, cv2.COLOR_BGR2RGB))
    display(Image(data=colab_image))


    # Morph the de-morphed image using the similarity model
    similarity_score = similarity_model.predict(np.expand_dims(demorphed_image, axis=0))[0][0]

    # Assuming a threshold of 0.5 for similarity
    print("the similarity score : ", similarity_score)
    if similarity_score >= 0.5:
        print("The de-morphed image is similar.")
    else:
        print("The de-morphed image is not similar.")

cv2.destroyAllWindows()